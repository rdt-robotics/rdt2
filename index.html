<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="RDT-2: Enabling Zero-Shot Cross-Embodiment Generalization by Scaling Up UMI Data">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RDT 2: Enabling Zero-Shot Cross-Embodiment Generalization by Scaling Up UMI Data</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <!-- <link rel="stylesheet" href="./static/css/fontawesome.all.min.css"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation"> -->
  <!-- <div class="navbar-brand"> -->
  <!-- <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false"> -->
  <!-- <span aria-hidden="true"></span> -->
  <!-- <span aria-hidden="true"></span> -->
  <!-- <span aria-hidden="true"></span> -->
  <!-- </a> -->
  <!-- </div> -->
  <!-- <div class="navbar-menu"> -->
  <!-- <div class="navbar-start" style="flex-grow: 1; justify-content: center;"> -->
  <!-- <a class="navbar-item" href="https://github.com/thu-ml/"> -->
  <!-- <span class="icon"> -->
  <!-- <i class="fas fa-home"></i> -->
  <!-- </span> -->
  <!-- </a> -->

  <!-- </div> -->
  <!-- </nav> -->


  <!-- Hero Video Section - Full Width like Figure AI -->
  <section class="hero-video-section">
    <!-- Full Width Video Container -->
    <div class="hero-video-container">
      <div class="hero-video-placeholder">
        <video style="width:100%; height:auto; margin: 0%;" muted autoplay loop playsinline>
          <source src="./static/videos/background_compressed.mp4" type="video/mp4">
        </video>
        <div style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0, 0, 0, 0.1);"></div>
      </div>
      
      <!-- Overlay Content - Title, Date, and Links inside video -->
      <div class="hero-overlay-content">
        <div class="hero-content">
            <h1 class="hero-title">RDT 2: Enabling Zero-Shot Cross-Embodiment Generalization by Scaling Up UMI Data</h1>
            
            <!-- Author and Date Information -->
            <div class="hero-meta">
              <div class="hero-author">
                <a href="#author" class="author-link">RDT Team</a>
              </div>
              <span class="hero-date">September 26, 2025</span>
            </div>
            
            <!-- Action Links -->
            <div class="hero-links">
              <span class="link-block">
                <a href="https://github.com/thu-ml/RDT2" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/robotics-diffusion-transformer/rdt-2-68ce9ddbf7dc520a231220d5" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <img src="static/svg/hf.svg" alt="huggingface" width="24" height="24">
                  </span>
                  <span>Model</span>
                </a>
              </span>
              <span class="link-block" style="opacity: 0.6; pointer-events: none; cursor: default;">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <svg class="svg-inline--fa fa-database fa-w-14" aria-hidden="true" focusable="false"
                      data-prefix="fas" data-icon="database" role="img" xmlns="http://www.w3.org/2000/svg"
                      viewBox="0 0 448 512" data-fa-i2svg="">
                      <path fill="currentColor"
                        d="M448 73.143v45.714C448 159.143 347.667 192 224 192S0 159.143 0 118.857V73.143C0 32.857 100.333 0 224 0s224 32.857 224 73.143zM448 176v102.857C448 319.143 347.667 352 224 352S0 319.143 0 278.857V176c48.125 33.143 136.208 48.572 224 48.572S399.874 209.143 448 176zm0 160v102.857C448 479.143 347.667 512 224 512S0 479.143 0 438.857V336c48.125 33.143 136.208 48.572 224 48.572S399.874 369.143 448 336z">
                      </path>
                    </svg>
                  </span>
                  <span>Data</span>
                </a>
              </span>
              <span class="link-block" style="opacity: 0.6; pointer-events: none; cursor: default;">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://x.com/EthanNg51931527/status/1846933749071859771" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <i class="fa-brands fa-twitter"></i>                            
                  </span>
                  <span>Twitter</span>
                </a>
              </span>   
              <span class="link-block">
                <a href="discord.html" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <i class="fa-brands fa-discord"></i>
                  </span>
                  <span>Discord</span>
                </a>
              </span>
              <span class="link-block">
                <a href="feishu.html" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <svg t="1758621592506" class="icon" viewBox="0 0 1335 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4804" width="200" height="200"><path d="M616.34246923 637.06814707s83.08051941-41.33100723 179.38003464-141.42593244c20.30472345-21.08400898 101.26385431-114.00661917 215.7611347-143.8359461 25.61541119-6.6527916 107.70017706-34.31743588 241.39097699 5.7724876 4.12732837 1.24108457 0.92359808 6.76824114-1.86162726 10.33275202s-32.45580863 27.76566275-122.5499002 215.41478522c-7.2156091 15.253797-87.22227887 171.54388367-310.83399646 125.6526112-12.17994736-2.49660105-198.81888518-60.75542588-201.28662241-71.9107575zM363.78172951 90.125s-19.20795063 3.08828074-4.0263099 24.53307028c3.85313516 5.26739447 224.75178287 173.54982266 342.98674886 385.18362899 7.30219647 13.06025217 37.80979047-27.54919473 37.80979047-27.54919473s114.00661917-120.73156623 200.88254938-144.61523161c6.27757993-1.71731469 13.63750076-3.40576721 1.70288361-25.97619178-2.75636233-5.25296338-69.68834967-185.38342136-132.52187165-211.51835596z" p-id="4805" fill="#ffffff"></path><path d="M154.54350493 388.23066187s1.54413996-28.86243558 24.07127124-13.32001346c6.95584699 4.77673325 437.72769223 453.14023288 796.28572541 386.15052035 0 0 3.72325451 1.65959033-6.0899741 11.27078119-3.59337305 3.50678567-364.04189566 327.25672175-798.04633337 48.25799204 0 0-19.68418076-13.33444537-16.22068918-49.91758155z" p-id="4806" fill="#ffffff"></path></svg>
                  </span>
                  <span>Feishu</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#BibTeX" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"> 
                    <svg t="1758713357279" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4694" width="200" height="200"><path d="M156.09136 606.57001a457.596822 457.596822 0 0 1 221.680239-392.516385 50.844091 50.844091 0 1 1 50.844091 86.943396 355.90864 355.90864 0 0 0-138.804369 152.532274h16.77855a152.532274 152.532274 0 1 1-152.532274 152.532274z m406.752731 0a457.596822 457.596822 0 0 1 221.680239-392.007944 50.844091 50.844091 0 1 1 50.844091 86.943396 355.90864 355.90864 0 0 0-138.804369 152.532274h16.77855a152.532274 152.532274 0 1 1-152.532274 152.532274z" fill="#ffffff" p-id="4695"></path></svg>
                  </span>
                  <span>BibTeX</span>
                </a>
              </span>
            </div>
          </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
    
  </section> -->



  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Introducing RDT 2</h2>
        <div class="column is-full">
          <p class="content has-text-justified mb-4">
            RDT 2, the sequel to RDT-1B [<a href="https://rdt-robotics.github.io/rdt-robotics/">1</a>], is <i>the first foundation model</i> that can achieve <b>zero-shot deployment</b> on <b>unseen embodiments</b> for <b>simple open-vocabulary tasks</b> like picking, placing, pressing, wiping, etc. This milestone was made possible by multifaceted efforts:
          </p>
          <p class="content has-text-justified mb-4">
            <ul>
              <li><b>Hardware redesign:</b> We redesigned the UMI [<a href="https://umi-gripper.github.io/">2</a>] hardware by applying higher-strength materials and more precise tracking methods, ensuring its reliability for large-scale data collection.</li>
              <li><b>Large and diverse data:</b> We collected 10,000+ hours of human manipulation videos in 100+ different indoor scenes, covering the majority of household tasks that a gripper can do.</li>
              <li><b>VLA pretraining:</b> Employing Residual VQ as an action tokenizer, we pretrained Qwen2.5-VL-7B-Instruct [<a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct">3</a>] on our UMI dataset, enabling superior instruction-following capability.</li>
              <li><b>Diffusion distillation:</b> We trained the RDT model as an action expert with flow-matching loss and then distilled it into a one-step generator, realizing ultra-fast inference speed.</li>
            </ul>
          </p>
          <p class="content has-text-justified mb-4">
            Currently, we have open-sourced code and weights for RDT2-VQ and RDT2-FM. Other components, including data, code, and weights for other models, will be released shortly.
          </p>
          <!-- <div style="margin-top: 5%;"> -->
          <figure class="video-figure" style="margin-top: 5%;">
            <video style="width:100%; height:auto; margin: 0%;" controls muted loading="lazy" autoplay loop playsinline>
              <source src="./static/videos/demo_compressed.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Our introduction video of RDT 2.</figcaption>
          </figure>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Vision</h2>
        <div class="column is-full">
          <p class="content has-text-justified mb-4">
            <b>The path to embodied superintelligence requires a new paradigm.</b>
          </p>
          <p class="content has-text-justified mb-4">
            Teleoperation, even of the highest quality and zero embodiment gap, has significant drawbacks: it is expensive and non-portable. It is difficult to access diverse scenes and tasks for collecting data, which is necessary for training a universal model.
          </p>
          <p class="content has-text-justified mb-4">
            Our vision is to break free from these constraints. We imagine a future built on wearable systems that seamlessly capture the richness of human activity at a global scale. This approach won't just gather data; it will mirror the very fabric of how we interact with the physical world, providing the essential foundation for embodied superintelligence.
          </p>
          <p class="content has-text-justified mb-4">
            While the ultimate hardware for this vision is on its way, we take a foundational first step by scaling up embodiment-free human data with grippers.
          </p>
        </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">UMI Hardware</h2>
        <div class="column is-full">
          <p class="content has-text-justified mb-4">
            The original UMI [<a href="https://umi-gripper.github.io/">2</a>], manufactured using 3D printing, lacks the requisite strength for long-term, high-frequency data collection. To address this limitation, we redesigned the mechanical structure. The new product utilizes a robust nylon 66 and glass fiber composite material, fabricated using CNC precision machining. We abandoned the original SLAM tracking method since it frequently fails in texture-less indoor environments. Instead, we adopted an infrared light-based positioning system (HTC VIVE Tracker 3.0 [<a href="https://www.vive.com/us/accessory/tracker3/">4</a>]) to track the 6DoF pose of the end-effector.
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline loading="lazy">
                <source src="static/videos/umi.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Composition of our UMI hardware.</figcaption>
          </figure>
          <p class="content has-text-justified mb-4">
            Since our hardware provides a unified end-effector across robots and humans, the embodiment gap is minimized, and models trained using such UMI data can be <b>zero-shot</b> deployed on any robot arm. No tele-operation. No human data collection. No fine-tuning. It is totally plug-and-play. All you need to do is: purchase the specified camera and gripper, use the correct flange and 3D printed camera bracket for mounting, and align the TCP coordinate system.
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline loading="lazy">
                <source src="static/videos/deployment.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Easily deployable on any robot arm.</figcaption>
          </figure>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Dataset</h2>
        <div class="column is-full">
          <p class="content has-text-justified mb-4">
            We manufactured nearly <b>100</b> UMIs and distributed them to <b>100+</b> real-world home and office scenes for data collection. We collected <b>10,000+</b> hours of manipulation data, covering the vast majority of common human manipulation tasks*. Thanks to our hardware's portability and cheapness, we can collect the same amount of data at about <b>1/10 cost</b> and <b>5Ã— speed</b> of teleoperation**. Here, we visualize some example clips from the dataset:
          </p>
          
          <!-- Dataset Video Carousel -->
          <div class="dataset-carousel-container" id="datasetCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev" id="prevBtn">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track" id="carouselTrack">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/038_ep_20250615_150427_combined_6-38s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/038_ep_20250624_093057_combined_0-7s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/040_ep_20250628_114524_combined_0-7s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/044_ep_20250625_163518_combined_0-8s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/046_ep_20250705_131508_combined.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/058_ep_20250626_094940_combined.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/071_ep_20250604_155522_combined_0-12s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/071_ep_20250619_202150_combined_2-10s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/071_ep_20250623_114753_combined_1-6s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/084_ep_20250609_145231_combined_4-11s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/023_ep_20250621_143026_combined_2-20s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/033_ep_20250616_095612_combined.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/033_ep_20250619_094318_combined_0-11s.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/dataset/036_ep_20250621_135355_combined_0-7s.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next" id="nextBtn">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <!-- Caption Display Area -->
            <div class="video-caption-container">
              <span class="video-caption prompt" id="videoCaption">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
              <div class="indicator" data-index="2"></div>
              <div class="indicator" data-index="3"></div>
              <div class="indicator" data-index="4"></div>
              <div class="indicator" data-index="5"></div>
              <div class="indicator" data-index="6"></div>
              <div class="indicator" data-index="7"></div>
              <div class="indicator" data-index="8"></div>
              <div class="indicator" data-index="9"></div>
              <div class="indicator" data-index="10"></div>
              <div class="indicator" data-index="11"></div>
              <div class="indicator" data-index="12"></div>
              <div class="indicator" data-index="13"></div>
            </div>
          </div>
          <p class="content has-text-justified mb-4">
            Since our hardware provides a unified end-effector across robots and humans, the embodiment gap is minimized, and models trained using such UMI data can be <b>zero-shot</b> deployed on any robot arm. No tele-operation. No human data collection. No fine-tuning. It is totally plug-and-play. All you need to do is: purchase the specified camera and gripper, use the correct flange and 3D printed camera bracket for mounting, and align the TCP coordinate system.
          </p>
          <p class="content has-text-justified mb-4">
            *Due to hardware limitations, we excluded tasks involving water contact, heat contact, or requiring five-finger dexterity. We also removed tasks requiring large quantities of consumables, such as cooking. 
            <br>
            **Cost estimates include equipment cost and labor cost. Speed estimates include manipulation speed and speed of transfer between different locations.
          </p>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
        <div class="column is-full">
          <h2 class="title is-3">Training</h2>
          <p class="content mb-4">
            The training process can be divided into three stages.
          </p>
          <p class="content mb-4">
            <b>Stage 1</b>
          </p>
          <p class="content has-text-justified mb-4">
            In Stage 1, we trained Qwen2.5-VL-7B-Instruct [<a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct">3</a>], a VLM model once pretrained on Internet-scale text and image data, on pure UMI data (i.e., our 10,000-hour UMI dataset). The model accepts two wrist-view fisheye images and a language instruction as input, and outputs discrete action tokens. The action tokens were discretized from continuous robot actions (6DoF end-effector pose and gripper width of both hands) by residual vector quantization (RVQ) [<a href="https://arxiv.org/abs/1711.00937">5</a>][<a href="https://arxiv.org/abs/2012.09841">6</a>][<a href="https://arxiv.org/abs/2203.01941">7</a>]. 
          </p>
          <p class="content has-text-justified mb-4">
            We took several measures to stabilize VQ training and improve codebook utilization, including factorized codes, cosine similarity, EMA updates, and codebook restart [<a href="https://github.com/karpathy/deep-vector-quantization">8</a>][<a href="https://arxiv.org/abs/2107.03312">9</a>][<a href="https://arxiv.org/abs/2110.04627">10</a>]. We also decoupled the discretization of rotation, translation, and gripper width as we found it helpful to avoid conflicts among multiple training objectives. As a result, we efficiently compress an action chunk of 0.8 seconds long (30 Hz) into a fixed-length 27 tokens. At the same level of precision, this length is <b>1/3</b> that of FAST [<a href="https://www.physicalintelligence.company/research/fast">11</a>] and <b>1/8</b> that of binning [<a href="https://arxiv.org/abs/2212.06817">12</a>][<a href="https://arxiv.org/abs/2307.15818">13</a>].
          </p>
          <p class="content has-text-justified mb-4">
            The outcome model in this stage is named <i>RDT2-VQ</i>. It is slower than other RDT2 variants as it needs to generate 27 tokens autoregressively (i.e., 27 forward passes) to obtain an action chunk.
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline loading="lazy">
                <source src="static/videos/vla_pretrain.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Stage 1 (RDT2-VQ): pretrain VLM with discrete action tokens.</figcaption>
          </figure>
          <p class="content mb-4">
            <b>Stage 2</b>
          </p>
          <p class="content has-text-justified mb-4">
            In Stage 2, we replaced the RVQ with a 400M RDT model (an improved version of RDT-1B [<a href="https://rdt-robotics.github.io/rdt-robotics/">1</a>]) as an action expert, which attends to the Qwen backbone's KV during denoising, following the best practice in Ï€0 [<a href="https://www.physicalintelligence.company/blog/pi0">14</a>] and Ï€0.5 [<a href="https://www.physicalintelligence.company/blog/pi05">15</a>]. The model can generate continuous robot actions without discretization errors through five diffusion denoising steps. We copied the weights from the outcome of Stage 1 into the Qwen backbone, freezed it, and trained the RDT model with flow-matching loss.
          </p>
          <p class="content has-text-justified mb-4">
            The outcome model in this stage is named <i>RDT2-FM</i>. We then mixed a tiny amount of real-robot data of UR and Franka with the original UMI data for post-training. We call this post-trained model <i>RDT2-FM-Post</i> to distinguish it from the original. These two models are much faster than the first since they only require one forward pass of Qwen and five forward passes of the 400M RDT model. 
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline loading="lazy">
                <source src="static/videos/diffusion_train.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Stage 2 (RDT2-FM): train RDT action expert with flow-matching loss.</figcaption>
          </figure>
          <p class="content mb-4">
            <b>Stage 3</b>
          </p>
          <p class="content has-text-justified mb-4">
            In Stage 3, we distilled RDT2-FM into a one-step diffusion policy without performance drop, where the Qwen backbone still stayed frozen. The model can map pure noise directly to robot actions through only a single diffusion step, similar to GAN [<a href="https://arxiv.org/abs/1406.2661">16</a>].
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline loading="lazy">
                <source src="static/videos/speed.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Comparisons of inference speed between ours and baselines.</figcaption>
          </figure>
          <p class="content has-text-justified mb-4">
            The outcome model in this stage is named <i>RDT2-UltraFast</i>. The model is the fastest since it only requires one forward pass of Qwen and one forward pass of the 400M RDT model. This is crucial for many tasks that require real-time responses, such as playing table tennis.
          </p>
          <figure class="video-figure">
            <video autoplay loop muted playsinline>
                <source src="static/videos/distillation.mp4" type="video/mp4">
            </video>
            <figcaption class="video-caption">Stage 3 (RDT2-UltraFast): distill RDT2-FM into a one-step diffusion policy.</figcaption>
          </figure>
          <p class="content mb-4">
            <b>Model Family</b>
          </p>
          <p class="content has-text-justified mb-4">
            We list the model family of RDT2 as follows:
          </p>
          <p class="content has-text-justified mb-4">
            <ul style="list-style-type: disc; margin-left: 2%; margin-bottom: 2%;">
              <li><b>RDT2-VQ</b>: Stage 1, superior instruction following, slow inference, RL support, releasedðŸŽ‰</li>
              <li><b>RDT2-FM</b>: Stage 2, better performance, fast inference, no RL support for now, releasedðŸŽ‰</li>
              <li><b>RDT2-FM-Post</b>: Stage 2, twin of RDT2-FM, optimized performance on UR and Franka, comingðŸ”œ</li>
              <li><b>RDT2-UltraFast</b>: Stage 3, better performance, ultra-fast inference, no RL support for now, comingðŸ”œ</li>
            </ul>
          </p>
          <p class="content has-text-justified mb-4">
            More models and code, including reinforcement learning, are coming soon. Stay tuned!
          </p>
        </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>
      <div class="column is-full">
          <p class="content mb-4">
            <b>Phase Transition Point</b>
          </p>
          <p class="content has-text-justified mb-4">
            We invite you to witness the highlight moment of this project. 
            Fresh from training, RDT 2 demonstrates robust zero-shot generalization under the full <b>"4U"</b> conditions â€” <b>U</b>nseen embodiment, <b>U</b>nseen scene, <b>U</b>nseen object, and <b>U</b>nseen language. 
            We describe this as a <i>phase transition point</i>: behavior shifts from narrow specialist to genuine generalist.
          </p>
          <p class="content has-text-justified mb-4">
            The system accepts everyday, open-ended instructions and grounds abstract language in physical behavior. 
            While not yet perfect, this milestone is decisive: the scaling direction is correct, 
            and the model already shows the first clear signs of embodied superintelligence.
          </p>
            <div class="dataset-carousel-container" id="zeroShotCarousel">
              <div class="dataset-carousel">
                <button class="carousel-btn carousel-btn-prev">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientLeft7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
                <div class="carousel-track-container">
                  <div class="carousel-track">
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pick-146-203-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pick-035-047-2x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pickandplace-233-258-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pickandplace-237-304-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-shake-640-720-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-shake-245-350-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-wipetable-210-300-8x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-wipetable-727-805-8x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pickintobowl-110-140-8x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-wipeobject-432-458-8x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-press-550-610-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-press-111-145-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pickandplace-400-436-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick-035-050-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide active" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick-110-140-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick-115-125-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick-008-032-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/franka-pick-204-218-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>
                <button class="carousel-btn carousel-btn-next">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientRight7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
              </div>
              <div class="video-caption-container">
                <span class="video-caption prompt">Loading caption...</span>
              </div>
              <div class="carousel-indicators">
                <div class="indicator active" data-index="0"></div>
                <div class="indicator" data-index="1"></div>
                <div class="indicator" data-index="2"></div>
                <div class="indicator" data-index="3"></div>
                <div class="indicator" data-index="4"></div>
                <div class="indicator" data-index="5"></div>
                <div class="indicator" data-index="6"></div>
                <div class="indicator" data-index="7"></div>
                <div class="indicator" data-index="8"></div>
              </div>
            </div>
            <p class="content has-text-justified mb-4">
              You can issue simple natural-language instructions, 
              and the model analyzes the concepts and maps them to precise control without task-specific scripting. 
              In contrast, traditional pipelines typically require predefined controllers and known configurations for each task.
            </p>
            <div class="dataset-carousel-container" id="zeroShotLanguageCarousel">
              <div class="dataset-carousel">
                <button class="carousel-btn carousel-btn-prev">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientLeft7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
                <div class="carousel-track-container">
                  <div class="carousel-track">
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-picksame-305-322-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-picksame-437-450-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick_slow-000-030-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ur-pick_steady-000-017.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>
                <button class="carousel-btn carousel-btn-next">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientRight7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
              </div>
              <div class="video-caption-container">
                <span class="video-caption prompt">Loading caption...</span>
              </div>
              <div class="carousel-indicators">
                <div class="indicator active" data-index="0"></div>
                <div class="indicator" data-index="1"></div>
              </div>
            </div>
            <p class="content has-text-justified mb-4">
              Across changes in scene layout, lighting, and surface height, 
              behavior remains stable and consistent: it attends to task-relevant cues 
              (object size, pose, reachable workspace) rather than incidental variation.
            </p>
            <div class="dataset-carousel-container" id="zeroShotSceneCarousel">
              <div class="dataset-carousel">
                <button class="carousel-btn carousel-btn-prev">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientLeft7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
                <div class="carousel-track-container">
                  <div class="carousel-track">
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/ur-pick_ds-235-248-4x.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/ur-pick_ds-222-246-4x.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/copy_5E21F282-C92C-467E-8FDC-629E0CD6B5F3.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/copy_51C7B1AB-AA00-465D-AC0D-A39EEB287600.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="carousel-slide" style="display: flex; gap: 0;">
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/copy_BC2EB863-EC6E-4188-A56F-3D7305BC1116.mp4" type="video/mp4">
                      </video>
                      <video autoplay muted loop playsinline loading="lazy" style="width: 50%; flex-shrink: 0;">
                        <source src="static/videos/zero-shot/ds/copy_D783D8B8-0A6D-40E3-B162-99E6C736DFFF.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>
                <button class="carousel-btn carousel-btn-next">
                  <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                      <linearGradient id="arrowGradientRight7" x1="0%" y1="0%" x2="0%" y2="100%">
                        <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                        <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                      </linearGradient>
                    </defs>
                    <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                  </svg>
                </button>
              </div>
              <div class="video-caption-container">
                <span class="video-caption prompt">Loading caption...</span>
              </div>
              <div class="carousel-indicators">
                <div class="indicator active" data-index="0"></div>
                <div class="indicator" data-index="1"></div>
                <div class="indicator" data-index="2"></div>
              </div>
            </div>
          
        </div>

        <div class="column is-full">
          <p class="content mb-4">
            <b>Capability Boundary</b>
          </p>
          <p class="content has-text-justified mb-4">
            To get a glimpse of the in-distribution performance of RDT2-UltraFast, 
            we curated a series of six challenging downstream tasks. 
            These benchmarks were designed to probe the limits of the model in 
            real-world scenarios demanding exceptional speed, 
            precision, and adaptability.
          </p>
          <p class="content has-text-justified mb-4">
            The archery challenge, in particular, presents an extreme test of reaction time. 
            The task requires intercepting an arrow shot from a 20-pound bow at a distance of 15 meters, 
            a feat that is exceptionally difficult, if not impossible, for a human. 
            Our model accomplished this formidable objective with a reaction time of about <b>100 milliseconds</b> (inference time + camera latency), 
            nearly the fastest recorded human reaction.
            This achievement demonstrates potential in high-stakes, rapid-response scenarios.
          </p>
          <div class="dataset-carousel-container" id="arrowCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft3" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft3)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/arrow.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/arrow_countdown.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight3" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight3)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
            </div>
          </div>

          <p class="content has-text-justified mb-4">
          The subsequent two tasks necessitated not only reaction but also high-precision control and fine-grained coordination. 
          In the incense extinguishing task, the model was required to swing a flame at high velocity, 
          continuously monitoring its state until it was fully extinguished. 
          The execution of this task demanded a trajectory of remarkable continuity and smoothness; 
          any pause or hesitation will give the flame enough time to reignite.
          </p>

          <div class="dataset-carousel-container" id="incenseCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft4" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft4)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/incense_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/incense_close_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight4" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight4)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
            </div>
          </div>
          
          <p class="content has-text-justified mb-4">
          In the table tennis task, our model demonstrated outstanding predictive capabilities. 
          This was accomplished despite the robot arm's maximum velocity of <b>1 m/s</b>, 
          a figure less than one-tenth of a human's arm speed. 
          To compensate for this physical limitation, the robot must accurately predict the ball's trajectory in advance and 
          plan its own swing path â€” all of which emerges automatically during end-to-end training without any hand-crafted prior.
          </p>

          <div class="dataset-carousel-container" id="pingpongCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft5" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft5)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/pingpong.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/pingpong_slow.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight5" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight5)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
            </div>
          </div>

          <p class="content has-text-justified mb-4">
            Further evaluations were conducted to probe RDT2-UltraFast's proficiency in manipulating deformable objects. 
            Such objects, characterized by their near-infinite degrees of freedom, 
            present substantial challenges to previous paradigms that rely on explicit computer graphics models or motion planning. 
            The inherent complexities suggest that an end-to-end training approach, such as the one employed by RDT 2, 
            may be uniquely suited to mastering these tasks.
          </p>

          <div class="dataset-carousel-container" id="unzipCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft6" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft6)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/unzip_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/unzip_gopro_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/unzip_close_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight6" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight6)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
              <div class="indicator" data-index="2"></div>
            </div>
          </div>

          <p class="content has-text-justified mb-4">
            In the fabric folding task, the model exhibited an ability to understand and manipulate the complex dynamics of cloth. 
            The task required not only precise control but also an intuitive grasp of how the fabric would respond to various manipulations. 
            Besides, we observed a remarkable degree of generalization. The model autonomously adapted its manipulation strategy to fold 
            previously unseen garments of varying textures and sizes successfully.
          </p>

          <div class="dataset-carousel-container" id="foldCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft7" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/fold_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/fold_orange_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/fold_blue_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                  <div class="carousel-slide">
                    <video muted loop playsinline loading="lazy">
                      <source src="./static/videos/fold_black_compressed.mp4" type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight7" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight7)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
              <div class="indicator" data-index="1"></div>
              <div class="indicator" data-index="2"></div>
              <div class="indicator" data-index="3"></div>
            </div>
          </div>

          <p class="content has-text-justified mb-4">
            The final experiment assessed the performance on a long-horizon, multi-stage task: setting a table according to human instructions. 
            While long-range tasks are often susceptible to the accumulation of errors, 
            RDT2-UltraFast demonstrated the ability to avoid deviations from the intended plan. 
            We hypothesize that this resilience stems from the extensive and diverse scenarios encountered during pre-training, 
            which effectively mitigates the out-of-distribution (OOD) problem.
          </p>
          
          <div class="dataset-carousel-container" id="plateCarousel">
            <div class="dataset-carousel">
              <button class="carousel-btn carousel-btn-prev">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientLeft8" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M19 12H5M5 12L12 19M5 12L12 5" stroke="url(#arrowGradientLeft8)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
              <div class="carousel-track-container">
                <div class="carousel-track">
                  <div class="carousel-slide active">
                    <video autoplay muted loop playsinline loading="lazy">
                      <source src="./static/videos/plate.mp4" type="video/mp4">
                    </video>
                  </div>

                </div>
              </div>
              <button class="carousel-btn carousel-btn-next">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                  <defs>
                    <linearGradient id="arrowGradientRight8" x1="0%" y1="0%" x2="0%" y2="100%">
                      <stop offset="0%" style="stop-color:#58D8FB;stop-opacity:1" />
                      <stop offset="100%" style="stop-color:#BE6AEF;stop-opacity:1" />
                    </linearGradient>
                  </defs>
                  <path d="M5 12H19M19 12L12 5M19 12L12 19" stroke="url(#arrowGradientRight8)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
              </button>
            </div>
            <div class="video-caption-container">
              <span class="video-caption prompt">Loading caption...</span>
            </div>
            <div class="carousel-indicators">
              <div class="indicator active" data-index="0"></div>
            </div>
          </div>

        </div>
    </div>
    </div>
  </section>

  <!-- <section class="section">
    <div class="container is-max-desktop">
        <div class="column is-full">
          <h2 class="title is-3">Quantitative Comparison with Baselines</h2>
          <p class="content has-text-justified mb-4">
            ðŸš§We are still working on it. Stay tuned!
          </p>
        </div>
    </div>
  </section> -->

<section class="section" id="author">
    <div class="container is-max-desktop">
        <div class="column is-full">
          <h2 class="title is-3">Author Team</h2>
          <p class="content mb-4">
            <b>Core Team</b>
          </p>
          <p class="content has-text-justified mb-4">
            We are proud to note that all core team members contributed equally to the success of this project.
            <ul style="list-style-type: disc; margin-left: 2%; margin-bottom: 2%;">
              <li>Songming Liu: Team Leader, Data Quality, Model, DEMO Screenwriter & Editor (part)</li>
              <li>Bangguo Li: Data Collection, Annotation, Deployment, DEMO Tech.</li>
              <li>Kai Ma: UMI Hardware, Data Collection, RL, Deployment</li>
              <li>Lingxuan Wu: Data Curation, Model, Training</li>
            </ul>
          </p>

          <p class="content mb-4">
            <b>Other Contributors</b>
          </p>
          <p class="content has-text-justified mb-4">
            Hengkai Tan, Xiao Ouyang, Zhengyi Wang, Huayu Chen
          </p>

          <p class="content mb-4">
            <b>Advisors</b>
          </p>
          <p class="content has-text-justified mb-4">
            Hang Su, Jun Zhu
          </p>
        </div>
    </div>
    <!--/ Abstract. -->
  </section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title is-3">Citation</h2>
        <p class="content has-text-justified mb-4">
            If you find our work helpful, please cite us:
        </p>
        <div class="bibtex-container">
            <pre><code id="bibtex-code">@software{rdt2,
    title={RDT2: Enabling Zero-Shot Cross-Embodiment Generalization by Scaling Up UMI Data},
    author={RDT Team},
    url={https://github.com/thu-ml/RDT2},
    month={September},
    year={2025}
}</code></pre>
            <button onclick="copyToClipboard()" class="copy-button">
                <!-- ç²˜è´´å›¾æ ‡ï¼Œå¯ä»¥ä½¿ç”¨Font Awesome å›¾æ ‡åº“ -->
                <i class="fa fa-copy" aria-hidden="true"></i>
            </button>
        </div>
        <p class="content has-text-justified mb-4">
            Thank you!
        </p>
    </div>
</section>

<!-- å¼•å…¥Font Awesomeæ ·å¼è¡¨ -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

<script>
function copyToClipboard() {
    var copyText = document.getElementById("bibtex-code").innerText;
    navigator.clipboard.writeText(copyText).then(function() {
        alert("Copied to clipboard!");
    }, function(err) {
        console.error('Unable to copy text:', err);
    });
}
</script>


  <footer class="footer">
    <div class="container">
      <!-- <div class="content has-text-centered">
        <p>We borrowed the page template from <a href="https://nerfies.github.io/"><span class="dnerf">Nerfies</span></a>.</p>
      </div> -->
    </div>
  </footer>

  <!-- Dataset Video Carousel JavaScript -->
  <script src="./static/js/carousel.js"></script>
  
  <!-- Apple-style button glow effect -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      // Add mouse tracking glow effect to all dark buttons
      const buttons = document.querySelectorAll('.button.is-dark');
      
      buttons.forEach(button => {
        button.addEventListener('mousemove', function(e) {
          const rect = button.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const y = e.clientY - rect.top;
          
          // Update the position of the glow effect
          button.style.setProperty('--mouse-x', x + 'px');
          button.style.setProperty('--mouse-y', y + 'px');
          
          // Add active class for gradient border
          button.classList.add('glow-active');
        });
        
        button.addEventListener('mouseleave', function() {
          // Remove active class when mouse leaves
          button.classList.remove('glow-active');
        });
        
        button.addEventListener('mouseenter', function(e) {
          const rect = button.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const y = e.clientY - rect.top;
          
          button.style.setProperty('--mouse-x', x + 'px');
          button.style.setProperty('--mouse-y', y + 'px');
        });
      });
    });
  </script>
  
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const datasetCarousel = new VideoCarousel({
        containerId: 'datasetCarousel',
        loadCaptionsFromFile: true,
        videoNames: [
          '038_ep_20250615_150427_combined_6-38s',
          '038_ep_20250624_093057_combined_0-7s',
          '040_ep_20250628_114524_combined_0-7s',
          '044_ep_20250625_163518_combined_0-8s',
          '046_ep_20250705_131508_combined',
          '058_ep_20250626_094940_combined',
          '071_ep_20250604_155522_combined_0-12s',
          '071_ep_20250619_202150_combined_2-10s',
          '071_ep_20250623_114753_combined_1-6s',
          '084_ep_20250609_145231_combined_4-11s',
          '023_ep_20250621_143026_combined_2-20s',
          '033_ep_20250616_095612_combined',
          '033_ep_20250619_094318_combined_0-11s',
          '036_ep_20250621_135355_combined_0-7s'
        ]
      });
      
      const zeroShotCarousel = new VideoCarousel({
        containerId: 'zeroShotCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/zero-shot/ur-pick-008-032-4x.mp4',
            caption: 'Left: "Pick up the small green bottle using the right hand." â€” RDT-VQ, 4x speed <br>Right: "Pick up the black bottle using the right hand." â€” RDT-VQ, 2x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-035-047-2x.mp4',
            caption: 'Left: "Pick up the brown box using the right hand. Put the brown box on the purple towel using the right hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the red fruit using the right hand. Put the red fruit on the purple towel using the right hand." â€” RDT-FM, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-146-203-4x.mp4',
            caption: 'Left: "Shake the white bottle using the right hand." â€” RDT-VQ, 4x speed <br>Right: "Shake the plastic bottle using the right hand." â€” RDT-VQ, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Wipe the table using the blue towel with the left hand." â€” RDT-VQ, 8x speed <br>Right: "Wipe the table using the blue towel with the right hand." â€” RDT-VQ, 8x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Pick up the banana using the right hand. Put the banana into the bowl using the right hand." â€” RDT-VQ, 8x speed <br>Right: "Pick up the pink towel using the left hand. Wipe the bowl with the pink towel using the left hand." â€” RDT-VQ, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Press the keyboard using the left hand." â€” RDT-VQ, 4x speed <br>Right: "Press the keyboard using the left hand." â€” RDT-VQ, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Pick up the green vegetable using the right hand. Put the vegetable on the paper box using the left hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the blue stapler using the right hand." â€” RDT-FM, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Pick up the green vegetable using the right hand." â€” RDT-VQ, 4x speed <br>Right: "Pick up the towel using the right hand." â€” RDT-VQ, 4x speed'
          },
          {
            src: './static/videos/zero-shot/franka-pick-204-218-4x.mp4',
            caption: 'Left: "Pick up the tissue box using the left hand." â€” RDT-VQ, 4x speed <br>Right: "Pick up the white towel using the right hand." â€” RDT-FM, 4x speed'
          },
        ]
      });
      const zeroShotLanguageCarousel = new VideoCarousel({
        containerId: 'zeroShotLanguageCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/zero-shot/ur-picksame-305-322-4x.mp4',
            caption: 'Left : "Pick up the blue toy with the right hand." â€” RDT-VQ, 4x speed <br>Right: "Pick up the blue toy with the left hand." â€” RDT-VQ, 4x speed'
          },
          {
            src: './static/videos/zero-shot/ur-picksame-437-450-4x.mp4',
            caption: 'Left : "Pick up the cabbage slowly with the right hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the cabbage steadily with the right hand." â€” RDT-FM, 4x speed'
          },
        ]
      });
      const zeroShotSceneCarousel = new VideoCarousel({
        containerId: 'zeroShotSceneCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/zero-shot/ds/ur-pick_ds-235-248-4x.mp4',
            caption: 'Left : "Pick up the pink snack cup with the left hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the red snack bag with the right hand." â€” RDT-FM, 4x speed'
          },
          {
            src: './static/videos/zero-shot/ds/ur-pick_ds-222-246-4x.mp4',
            caption: 'Left : "Pick up the banana with the left hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the pink snack bag with the right hand." â€” RDT-FM, 4x speed'
          },
          {
            src: './static/videos/zero-shot/ds/ur-pick_ds-222-246-4x.mp4',
            caption: 'Left : "Pick up the golden snack with the right hand." â€” RDT-FM, 4x speed <br>Right: "Pick up the green snack steadily with the left hand." â€” RDT-FM, 4x speed'
          },
        ]
      });
      const arrowCarousel = new VideoCarousel({
        containerId: 'arrowCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/arrow.mp4',
            caption: '"Use a shield to block incoming arrows." â€” over-the-shoulder shot'
          },
          {
            src: './static/videos/arrow_countdown.mp4', 
            caption: '"Use a shield to block incoming arrows." â€” side shot'
          }
        ]
      });

      const incenseCarousel = new VideoCarousel({
        containerId: 'incenseCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/incense_compressed.mp4',
            caption: '"Grab the incense, light it, shake it quickly to extinguish it, and finally insert it into the incense burner." â€” 1x speed'
          },
          {
            src: './static/videos/incense_close_compressed.mp4',
            caption: '"Grab the incense, light it, shake it quickly to extinguish it, and finally insert it into the incense burner." â€” 1x speed'
          }
        ]
      });

      const pingpongCarousel = new VideoCarousel({
        containerId: 'pingpongCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/pingpong.mp4',
            caption: '"Use a paddle to hit the table tennis ball back." â€” 1x speed'
          },
          {
            src: './static/videos/pingpong_slow.mp4',
            caption: '"Use a paddle to hit the table tennis ball back." â€” 0.05x speed'
          }
        ]
      });

      const unzipCarousel = new VideoCarousel({
        containerId: 'unzipCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/unzip_compressed.mp4',
            caption: '"Unzip the backpack." â€” 1x speed'
          },
          {
            src: './static/videos/unzip_gopro_compressed.mp4',
            caption: '"Unzip the backpack." â€” GoPro view, 1x speed'
          },
          {
            src: './static/videos/unzip_close_compressed.mp4',
            caption: '"Unzip the backpack." â€” close-up view, 1x speed'
          }
        ]
      });

      const foldCarousel = new VideoCarousel({
        containerId: 'foldCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/fold_compressed.mp4',
            caption: '"Fold the right and left sleeves inwards, then fold the bottom of the garment upwards." â€” seen, 1x speed'
          },
          {
            src: './static/videos/fold_orange_compressed.mp4',
            caption: '"Fold the right and left sleeves inwards, then fold the bottom of the garment upwards." â€” unseen, 1x speed'
          },
          {
            src: './static/videos/fold_blue_compressed.mp4',
            caption: '"Fold the right and left sleeves inwards, then fold the bottom of the garment upwards." â€” unseen, 1x speed'
          },
          {
            src: './static/videos/fold_black_compressed.mp4',
            caption: '"Fold the right and left sleeves inwards, then fold the bottom of the garment upwards." â€” unseen, 1x speed'
          }
        ]
      });

      const plateCarousel = new VideoCarousel({
        containerId: 'plateCarousel',
        loadCaptionsFromFile: false,
        videos: [
          {
            src: './static/videos/plate.mp4',
            caption: 'The robot sets the table step by step according to human instructions. â€” 16x speed'
          }
        ]
      });
      
    });
  </script>

</body>

</html>
